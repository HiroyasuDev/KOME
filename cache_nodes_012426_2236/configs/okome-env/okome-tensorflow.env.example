# OKOME (192.168.86.25) â€” TensorFlow Serving integration
# Source this or copy into your OKOME app env (e.g. .env or systemd Environment=).
# Ensures OKOME can call CORE GPU 192.168.86.30 for TensorFlow inference.

# TensorFlow Serving REST (required for HTTP predict)
export TENSORFLOW_SERVING_URL="http://192.168.86.30:8501"

# TensorFlow Serving gRPC (optional; use if OKOME uses gRPC client)
export TENSORFLOW_SERVING_GRPC="192.168.86.30:8500"

# Ensure firewall on 192.168.86.30 allows 8500/8501 from 192.168.86.25.
# Run: cache_nodes_012426_2236/scripts/okome-env/ensure-firewall-25-to-30.sh on .30
